{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#<center>**SỬ DỤNG MÔ HÌNH XXX VÀ YYY TÌM KIẾM VĂN BẢN TIẾNG ANH**\n","#<center>**Môn học:** Truy xuất thông tin\n","#<center>**Mã lớp:** CS419.N11\n","---\n","**Danh sách sinh viên thực hiện:**\n","1.  Phan Thanh Hải - 18520705\n","2. Nguyễn Hoàng Long - 20520239"],"metadata":{"id":"tiQyzrCF8dk4"}},{"cell_type":"markdown","source":["**Lưu ý:**\n","\n","*   Quy cách đặt tên các thành phần cơ bản của chương trình theo hướng dẫn sau đây: https://peps.python.org/pep-0008/.\n","*   Sử dụng tiếng Anh để đặt tên biến, tên hàm, v.v... Chỉ sử dụng tiếng Việt để comment, nếu cần."],"metadata":{"id":"9G0kK2_fyAJ0"}},{"cell_type":"markdown","source":["# **1. Chèn các thư viện cần thiết**"],"metadata":{"id":"XtQQl40FAkb6"}},{"cell_type":"code","source":["import os\n","import re\n","import nltk\n","nltk.download('all')\n","from natsort import natsorted\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.corpus import stopwords"],"metadata":{"id":"PNmEcm7xAuzv","executionInfo":{"status":"ok","timestamp":1677849622010,"user_tz":-420,"elapsed":4448,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f18ad0e-b824-4b32-9175-00cffccf7481"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Package abc is already up-to-date!\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Package alpino is already up-to-date!\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n","[nltk_data]    |       to-date!\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n","[nltk_data]    |       up-to-date!\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package basque_grammars is already up-to-date!\n","[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n","[nltk_data]    |   Package bcp47 is already up-to-date!\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package book_grammars is already up-to-date!\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Package brown is already up-to-date!\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Package brown_tei is already up-to-date!\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Package cess_cat is already up-to-date!\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Package cess_esp is already up-to-date!\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Package chat80 is already up-to-date!\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package city_database is already up-to-date!\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Package cmudict is already up-to-date!\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package comparative_sentences is already up-to-\n","[nltk_data]    |       date!\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    |   Package comtrans is already up-to-date!\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Package conll2000 is already up-to-date!\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Package conll2002 is already up-to-date!\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    |   Package conll2007 is already up-to-date!\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Package crubadan is already up-to-date!\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package dependency_treebank is already up-to-date!\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Package dolch is already up-to-date!\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package europarl_raw is already up-to-date!\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package extended_omw is already up-to-date!\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Package floresta is already up-to-date!\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package framenet_v15 is already up-to-date!\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package framenet_v17 is already up-to-date!\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Package gazetteers is already up-to-date!\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Package genesis is already up-to-date!\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Package gutenberg is already up-to-date!\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Package ieer is already up-to-date!\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Package inaugural is already up-to-date!\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Package indian is already up-to-date!\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    |   Package jeita is already up-to-date!\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Package kimmo is already up-to-date!\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    |   Package knbc is already up-to-date!\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package large_grammars is already up-to-date!\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Package mac_morpho is already up-to-date!\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    |   Package machado is already up-to-date!\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    |   Package masc_tagged is already up-to-date!\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n","[nltk_data]    |       to-date!\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package moses_sample is already up-to-date!\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package movie_reviews is already up-to-date!\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Package mte_teip5 is already up-to-date!\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Package names is already up-to-date!\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Package nps_chat is already up-to-date!\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Package omw is already up-to-date!\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    |   Package omw-1.4 is already up-to-date!\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Package paradigms is already up-to-date!\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Package pe08 is already up-to-date!\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package perluniprops is already up-to-date!\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Package pil is already up-to-date!\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Package pl196x is already up-to-date!\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Package porter_test is already up-to-date!\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Package ppattach is already up-to-date!\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package problem_reports is already up-to-date!\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    |   Package propbank is already up-to-date!\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Package pros_cons is already up-to-date!\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Package ptb is already up-to-date!\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Package punkt is already up-to-date!\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Package qc is already up-to-date!\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    |   Package reuters is already up-to-date!\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Package rslp is already up-to-date!\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Package rte is already up-to-date!\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sample_grammars is already up-to-date!\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    |   Package semcor is already up-to-date!\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Package senseval is already up-to-date!\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sentence_polarity is already up-to-date!\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sentiwordnet is already up-to-date!\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Package shakespeare is already up-to-date!\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package sinica_treebank is already up-to-date!\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Package smultron is already up-to-date!\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package snowball_data is already up-to-date!\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package spanish_grammars is already up-to-date!\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Package state_union is already up-to-date!\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Package stopwords is already up-to-date!\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package subjectivity is already up-to-date!\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Package swadesh is already up-to-date!\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Package switchboard is already up-to-date!\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Package tagsets is already up-to-date!\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Package timit is already up-to-date!\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Package toolbox is already up-to-date!\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Package treebank is already up-to-date!\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package twitter_samples is already up-to-date!\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Package udhr is already up-to-date!\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Package udhr2 is already up-to-date!\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package unicode_samples is already up-to-date!\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package universal_tagset is already up-to-date!\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n","[nltk_data]    |       date!\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package vader_lexicon is already up-to-date!\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Package verbnet is already up-to-date!\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Package verbnet3 is already up-to-date!\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Package webtext is already up-to-date!\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Package wmt15_eval is already up-to-date!\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package word2vec_sample is already up-to-date!\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Package wordnet is already up-to-date!\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    |   Package wordnet2021 is already up-to-date!\n","[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n","[nltk_data]    |   Package wordnet2022 is already up-to-date!\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    |   Package wordnet31 is already up-to-date!\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Package wordnet_ic is already up-to-date!\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Package words is already up-to-date!\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Package ycoe is already up-to-date!\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1FeT_Gr2rDCa","executionInfo":{"status":"ok","timestamp":1677849625423,"user_tz":-420,"elapsed":3420,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"6c361fe2-45f0-46f9-c64d-9f90f347890d"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# **2. Đọc dữ liệu**"],"metadata":{"id":"mLv_VCvAA4Sv"}},{"cell_type":"code","source":["'''\n","Input: chuỗi kí tự documents_path là đường dẫn tới thư mục chứa các tài liệu\n","Output: danh sách documents, trong đó mỗi phần tử của danh sách là toàn bộ chuỗi kí tự của tập tài liệu tương ứng\n","Ví dụ: documents = ['the specific configuration . the experiment . ',\n","                    'the discussion here is restricted . two dimensional incompressible steady flow .']\n","'''\n","def read_documents(documents_path):\n","    documents = []\n","    os.chdir(documents_path)\n","    # Use natsorted() for natural sorting of file names\n","    for file in natsorted(os.listdir()):\n","    # Check whether file is in text format or not\n","        if file.endswith(\".txt\"):\n","            file_path = f\"{documents_path}/{file}\"\n","            with open(file_path, 'r') as f:\n","                documents.append(f.read())    \n","    return documents"],"metadata":{"id":"muOTOmSctBob"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documents_path = '/content/drive/MyDrive/FOLDER MÔN HỌC/HK1(2022-2023)/CS419.N11 - Truy xuất thông tin/Bài tập/Cranfield'\n","documents = read_documents(documents_path)\n","print(documents[:5])"],"metadata":{"id":"-_VKzh3gAXuH","executionInfo":{"status":"ok","timestamp":1677848536763,"user_tz":-420,"elapsed":65791,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"04be3bb4-6d3e-4d24-f1a1-cc74f5bf7a46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['experimental investigation of the aerodynamics of a wing in a slipstream . an experimental study of a wing in a propeller slipstream was made in order to determine the spanwise distribution of the lift increase due to slipstream at different angles of attack of the wing and at different free stream to slipstream velocity ratios .  the results were intended in part as an evaluation basis for different theoretical treatments of this problem . the comparative span loading curves, together with supporting evidence, showed that a substantial part of the lift increment produced by the slipstream was due to a /destalling/ or boundary layer control effect .  the integrated remaining lift increment, after subtracting this destalling lift, was found to agree well with a potential flow theory . an empirical evaluation of the destalling effects was made for the specific configuration of the experiment . ', \"simple shear flow past a flat plate in an incompressible fluid of small viscosity . in the study of high speed viscous flow past a two dimensional body it is usually necessary to consider a curved shock wave emitting from the nose or leading edge of the body .  consequently, there exists an inviscid rotational flow region between the shock wave and the boundary layer .  such a situation arises, for instance, in the study of the hypersonic viscous flow past a flat plate .  the situation is somewhat different from prandtl's classical boundary layer problem . in prandtl's original problem the inviscid free stream outside the boundary layer is irrotational while in a hypersonic boundary layer problem the inviscid free stream must be considered as rotational .  the possible effects of vorticity have been recently discussed by ferri and libby .  in the present paper, the simple shear flow past a flat plate in a fluid of small viscosity is investigated .  it can be shown that this problem can again be treated by the boundary layer approximation, the only novel feature being that the free stream has a constant vorticity .  the discussion here is restricted to two dimensional incompressible steady flow . \", 'the boundary layer in simple shear flow past a flat plate . the boundary layer equations are presented for steady incompressible flow with no pressure gradient . ', 'approximate solutions of the incompressible laminar boundary layer equations for a plate in shear flow . the two dimensional steady boundary layer problem for a flat plate in a shear flow of incompressible fluid is considered . solutions for the boundary  layer thickness, skin friction, and the velocity distribution in the boundary layer are obtained by the karman pohlhausen technique .  comparison with the boundary layer of a uniform flow has also been made to show the effect of vorticity . ', 'one dimensional transient heat conduction into a double layer slab subjected to a linear heat input for a small time internal . analytic solutions are presented for the transient heat conduction in composite slabs exposed at one surface to a triangular heat rate .  this type of heating rate may occur, for example, during aerodynamic heating . ']\n"]}]},{"cell_type":"code","source":["'''\n","Input: chuỗi kí tự queries_path là đường dẫn tới tập tin chứa các câu truy vấn\n","Output: danh sách queries, trong đó mỗi phần tử của danh sách là toàn bộ chuỗi kí tự của câu truy vấn tương ứng\n","Ví dụ: queries = ['aeroelastic models of heated high speed aircraft .',\n","                  'with flight of high speed aircraft .']\n","'''\n","def read_queries(queries_path):\n","    with open(queries_path) as file:\n","        queries = file.readlines()\n","    # Mỗi dòng trong tập tin query.txt có cấu trúc [id]\\t[câu truy vấn]\n","    # -> Ta lấy câu truy vấn bằng cách tách từng dòng bởi dấu \\t và chỉ lấy phần sau sau dấu \\t\n","    for idx in range(len(queries)):\n","        queries[idx] = queries[idx][:-1].split(\"\\t\")[1]\n","    return queries"],"metadata":{"id":"tGI_OTqftK5j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["queries_path = '/content/drive/MyDrive/FOLDER MÔN HỌC/HK1(2022-2023)/CS419.N11 - Truy xuất thông tin/Bài tập/TEST/query.txt'\n","queries = read_queries(queries_path)\n","print(queries[:5])"],"metadata":{"id":"Lxzz754DCyoN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677848537409,"user_tz":-420,"elapsed":689,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"c042eacb-0e33-4447-fd88-7fa170ee91c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft .', 'what are the structural and aeroelastic problems associated with flight of high speed aircraft .', 'what problems of heat conduction in composite slabs have been solved so far .', 'can a criterion be developed to show empirically the validity of flow solutions for chemically reacting gas mixtures based on the simplifying assumption of instantaneous local chemical equilibrium .', 'what chemical kinetic system is applicable to hypersonic aerodynamic problems .']\n"]}]},{"cell_type":"code","source":["len(queries)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NPpYBiNxv5kx","executionInfo":{"status":"ok","timestamp":1677851606492,"user_tz":-420,"elapsed":840,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"c965dda9-e2ef-4cab-a684-7c3c2f37d8e4"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["225"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["'''\n","Input: chuỗi kí tự relevance_path là đường dẫn tới thư mục chứa kết quả truy vấn đúng\n","Output: từ điển relevance, trong đó:\n","+ thành phần khóa là id của câu truy vấn\n","+ thành phần value là danh sách id của tập tài liệu tương ứng với kết quả truy vấn đúng dựa trên id của câu truy vấn trên\n","Ví dụ: relevance = {1: [1, 2, 3]\n","                    2: [3, 4]}\n","'''\n","def read_relevance(relevance_path):\n","    relevance = {}\n","    os.chdir(relevance_path)\n","    idx = 1\n","    # Use natsorted() for natural sorting of file names\n","    for file in natsorted(os.listdir()):\n","    # Check whether file is in text format or not\n","        if file.endswith(\".txt\"):\n","            file_path = f\"{relevance_path}/{file}\"\n","            with open(file_path, 'r') as f:\n","                line = f.readlines()\n","                relevance[idx] = []\n","                for li in line:\n","                    temp = re.split(r\"[ \\t\\n]\\s*\", li)\n","                    relevance[idx].append(int(temp[1]))\n","        idx += 1\n","    return relevance"],"metadata":{"id":"hokCh9YzDjUn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["relevance_path = '/content/drive/MyDrive/FOLDER MÔN HỌC/HK1(2022-2023)/CS419.N11 - Truy xuất thông tin/Bài tập/TEST/RES'\n","relevance = read_relevance(relevance_path)\n","print(relevance)"],"metadata":{"id":"24rMjGdnF9Mr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677848542206,"user_tz":-420,"elapsed":4805,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"30e07ee3-743b-4568-89a7-0f5aaf6889e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{1: [184, 29, 31, 12, 51, 102, 13, 14, 15, 57, 378, 859, 185, 30, 37, 52, 142, 195, 875, 56, 66, 95, 462, 497, 858, 876, 879, 880, 486], 2: [12, 15, 184, 858, 51, 102, 202, 14, 52, 380, 746, 859, 948, 285, 390, 391, 442, 497, 643, 856, 857, 877, 864, 658, 486], 3: [5, 6, 90, 91, 119, 144, 181, 399, 485], 4: [236, 166, 488], 5: [552, 401, 1297, 1296, 488], 6: [99, 115, 257, 258, 491], 7: [20, 56, 57, 58, 19, 492], 8: [48, 122, 20, 58, 196, 354, 360, 197, 999, 1112, 1005, 492], 9: [21, 22, 550, 534], 10: [259, 405, 302, 436, 437, 438, 998, 1011, 493], 11: [27, 28, 262, 160, 20, 263, 654, 495], 12: [86, 194, 650, 649, 652, 624], 13: [64, 265, 65, 311, 496], 14: [64, 65, 496], 15: [463, 462, 497], 16: [266, 106, 196, 498], 17: [106, 196, 498], 18: [196, 197, 198, 498], 19: [32, 67, 164, 639, 715, 716, 719, 1379, 717, 499], 20: [87, 88, 104, 267, 268, 269, 270, 407, 408, 500], 21: [271, 16, 413, 414, 502], 22: [68, 502], 23: [900, 902, 200, 201, 601, 899, 903, 593, 199, 594, 901, 544, 597, 749, 917, 919, 1333, 634, 687, 698, 1290, 700, 704, 705, 1109, 1112, 1141, 1197, 1256, 1259, 1272, 1289, 892], 24: [46, 47, 92, 756], 25: [213, 212, 214, 215, 216, 276, 277, 426, 427, 511], 26: [145, 611, 376, 406, 565, 1076, 511], 27: [224, 278, 428, 512], 28: [224, 279, 512], 29: [250, 514, 609, 225, 793, 464, 465, 612, 466, 513], 30: [225, 464, 514, 466, 609, 612, 793, 513], 31: [776, 751], 32: [465, 249, 777, 778, 247, 250, 752], 33: [252, 431, 141, 516], 34: [252, 431, 672, 714, 799, 800, 516], 35: [166, 167, 132, 517], 36: [169, 168, 518], 37: [173, 188, 172, 97, 121, 187, 242, 409, 487, 519], 38: [24, 283, 552, 272, 557, 558, 553, 554, 555, 556, 536], 39: [272, 555, 24, 283, 552, 79, 207, 418, 557, 554, 556, 505, 1257, 536], 40: [24, 283, 552, 272, 85, 976, 557, 558, 553, 554, 555, 556, 536], 41: [288, 289, 433, 520], 42: [468, 467, 469, 470, 775, 521], 43: [467, 468, 39, 503, 775, 469, 521], 44: [302, 436, 437, 524], 45: [305, 570, 308, 481, 338, 1226, 1355, 1185, 629, 663, 798, 572, 525], 46: [305, 338, 344, 481, 84, 123, 1185, 623, 570, 798, 1226, 629, 663, 572, 1355, 525], 47: [304, 306, 307, 305, 629, 663, 308, 309, 310, 570, 798, 1185, 1355, 572, 525], 48: [439, 311, 316, 440, 187, 314, 315, 797, 798, 794, 265, 526], 49: [320, 478, 527], 50: [326, 629, 21, 94, 22, 306, 528], 51: [94, 23, 105, 381, 192, 326, 63, 494, 629, 261, 528], 52: [21, 22, 306, 326, 528], 53: [296, 33, 446, 447, 448, 449, 208, 297, 298, 299, 531], 54: [84, 24, 101, 294, 628, 661, 364, 365, 560, 123], 55: [16, 375, 460, 378, 255, 271, 376, 377, 562, 502, 538], 56: [380, 749, 1339, 14, 705, 779, 780, 379, 643, 686, 753], 57: [380, 593, 746, 914, 14, 379, 705, 779, 780, 704, 12, 15, 857, 859, 753], 58: [788, 785, 786, 787, 23, 381, 382, 784, 789, 754], 59: [788, 785, 786, 787, 754], 60: [475, 476, 527, 320, 478, 322], 61: [565, 566, 564, 1159, 661, 539], 62: [566, 567, 1084, 1078, 1081, 539], 63: [567, 564, 566, 539], 64: [390, 391, 627], 65: [2, 3, 128, 180, 323, 324, 418, 664, 629, 393, 394, 659, 4, 384, 1302, 388], 66: [664, 629, 180, 659, 660, 388], 67: [2, 3, 664, 629, 323, 324, 393, 128, 180, 394, 659, 389, 4, 1302, 388], 68: [662, 101, 460, 661, 62, 628], 69: [458, 570, 977, 62, 336, 540], 70: [333, 568, 570, 62, 101, 283, 565, 24, 977, 307, 540], 71: [569, 571, 1355, 101, 655, 1213, 798, 572, 540], 72: [21, 324, 630, 94, 664, 304, 128, 323, 663, 570, 494, 305, 309, 571, 655, 388, 62, 629], 73: [332, 572, 578, 573, 574, 421, 25, 317, 577, 401, 625, 160, 1213, 1304, 1198, 655, 1355, 68, 571, 1252, 541], 74: [576, 656, 575, 317, 574, 578, 541], 75: [667, 324, 378, 666, 670, 630], 76: [378, 667, 324, 666, 670, 1391, 329, 630], 77: [668, 666, 667, 670, 329, 1391, 630], 78: [588, 589, 590, 543], 79: [597, 598, 688, 708, 713, 544], 80: [594, 597, 596, 598, 544], 81: [672, 799, 631], 82: [676, 677, 678, 679, 205, 632], 83: [680, 681, 682, 683, 633], 84: [606, 406, 608, 142, 294, 354, 522, 962, 1192, 1213, 873, 546], 85: [608, 406, 606, 710, 546], 86: [594, 790, 755], 87: [606, 611, 562, 50, 236, 609, 612, 406, 547], 88: [613, 614, 615, 616, 617, 618, 548], 89: [793, 794, 797, 795, 796, 420, 757], 90: [794, 797, 798, 793, 796, 291, 800, 1187, 256, 311, 335, 1364, 1367, 757], 91: [252, 801, 797, 799, 800, 793, 794, 1154, 672, 757], 92: [802, 803, 808, 809, 811, 804, 805, 806, 253, 1247, 807, 810, 1243, 758], 93: [691, 635], 94: [24, 283, 294, 559, 689, 690, 101, 1393, 354, 1104, 1161, 1395, 635], 95: [283, 662, 635], 96: [703, 704, 705, 698, 699, 700, 1289, 779, 701, 702, 706, 792, 1339, 637], 97: [699, 700, 701, 698, 1289, 702, 703, 779, 1339, 681, 637], 98: [713, 708, 709, 711, 712, 638], 99: [717, 719, 1001, 1379, 639], 100: [821, 822, 824, 820, 823, 825, 1122, 1051, 1121, 760], 101: [817, 818, 819, 820, 825, 824, 760], 102: [728, 913, 910, 911, 729], 103: [826, 828, 761], 104: [833, 834, 835, 836, 837, 762], 105: [848, 844, 845, 846, 847, 764], 106: [847, 846, 849, 844, 845, 764], 107: [725, 728, 729, 911, 720, 75, 909, 640], 108: [724, 726, 727, 75, 909, 720, 723, 640], 109: [860, 861, 606, 980, 12, 766], 110: [862, 863, 31, 1174, 766], 111: [15, 391, 864, 914, 392, 627, 658, 894], 112: [731, 730, 641], 113: [746, 748, 749, 265, 643], 114: [919, 916, 920, 921, 895], 115: [51, 185, 878, 874, 184], 116: [922, 360, 605, 927, 492, 896], 117: [360, 605, 896], 118: [923, 924, 925, 896], 119: [926, 897], 120: [829, 887, 890, 885, 886, 888, 889, 1146, 891, 769], 121: [885, 886, 1146, 887, 888, 890, 891, 769], 122: [931, 932, 934, 935, 936, 937, 938, 957, 1131, 898], 123: [966, 967, 941], 124: [967, 968, 964, 965, 941], 125: [969, 970, 971, 187, 973, 173, 974, 177, 972, 174, 997, 176, 409, 946, 992, 994, 995, 942], 126: [974, 1326, 187, 969, 970, 971, 972, 973, 942], 127: [101, 164, 981, 982, 983, 944], 128: [985, 990, 945], 129: [985, 987, 984, 988, 989, 986, 990, 945], 130: [766, 858, 859, 1008, 12, 948], 131: [1014, 1020, 1013, 1016, 1017, 1012, 1018, 1019, 950], 132: [1014, 1013, 1015, 1016, 1012, 1018, 1019, 1017, 951, 1023, 1020, 952, 1024, 1025, 1026, 950], 133: [1020, 1018, 1019, 1024, 1012, 1016, 1022, 950], 134: [1027, 1028, 951], 135: [1018, 1017, 1023, 1024, 1025, 1026, 950, 1016, 951], 136: [1021, 1022, 1034, 951], 137: [1029, 1034, 951, 1021, 952], 138: [846, 1036, 953], 139: [1031, 1032, 1035, 1037, 953], 140: [1038, 1039, 1041, 1042, 1043, 1044, 954], 141: [1038, 1041, 1043, 1044, 1039, 1042, 954], 142: [1042, 954], 143: [1043, 1044, 954], 144: [840, 1045, 763, 838, 839, 841, 955], 145: [763, 838, 839, 1045, 743, 852, 841, 955], 146: [840, 1045, 955], 147: [889, 1046, 1048, 1047, 1049, 1051, 1050, 843, 926, 822, 956], 148: [889, 1048, 1050, 1046, 1049, 843, 956], 149: [1057, 1058, 1059, 1052, 930, 931, 934, 936, 937, 938, 1131, 957], 150: [1074, 1075, 1062], 151: [687, 1076, 1074, 1075, 1077, 1062], 152: [1076, 1077, 569, 572, 687, 655, 1062], 153: [1078, 1083, 1084, 1080, 1081, 1082, 1085, 1063], 154: [1087, 1088, 1063], 155: [1103, 1100, 983, 1101, 1104, 1099, 1065], 156: [983, 1102, 1097, 1100, 274, 1096, 1098, 1099, 1103, 982, 1104, 553, 1101, 82, 1065], 157: [273, 1105, 1106, 93, 161, 302, 122, 666, 1107, 556, 25, 1011, 19, 35, 1355, 372, 410, 456, 36, 44, 215, 626, 1151, 354, 369, 370, 421, 557, 605, 655, 657, 689, 1307, 318, 423, 1304, 160, 482, 572, 1006], 158: [302, 1011, 552, 998, 1009, 1010, 273, 556, 1006], 159: [234, 1108, 1110, 1114, 1115, 1111, 1112, 231, 1066], 160: [1134, 1137, 1138, 1135, 1136, 1071], 161: [54, 1386, 562, 336, 55, 996, 489], 162: [111, 155, 460, 461, 54, 562, 458, 459, 489], 163: [20, 56, 57, 492], 164: [311, 415, 416, 798, 316, 335, 1364, 1367, 503], 165: [71, 72, 504], 166: [40, 41, 74, 207, 272, 418, 170, 1264, 504], 167: [274, 82, 509], 168: [217, 774, 750], 169: [118, 157, 774, 775, 750], 170: [139, 238, 239, 904, 906, 672, 893], 171: [252, 431, 141, 516], 172: [320, 321, 322, 476, 527], 173: [367, 451, 532], 174: [58, 411, 36, 423, 482, 533], 175: [351, 966, 967, 964, 965, 941], 176: [582, 583, 584, 585, 978, 586, 982, 542], 177: [588, 589, 592, 772, 590, 543], 178: [591, 590, 588, 589, 543], 179: [680, 681, 682, 683, 633], 180: [622, 619, 620, 621, 617, 616, 1150, 548], 181: [973, 974, 409, 997, 1061, 942], 182: [685, 686, 634], 183: [803, 808, 802, 807, 811, 253, 804, 805, 806, 809, 810, 1243, 1247, 758], 184: [32, 67, 715, 717, 716, 499, 1379, 639], 185: [858, 859, 857, 1008, 856, 15, 285, 894, 766, 948], 186: [1309, 1378, 923, 161, 421, 1377, 924, 1062, 1074, 1379, 1380, 1075, 225, 1280, 1305, 1304, 1188], 187: [838, 839, 840, 743, 842, 1045, 763], 188: [721, 722, 723, 75, 909, 724, 726, 725, 728, 729, 911, 640], 189: [395, 866, 869, 865, 868, 870, 867, 872, 873, 767], 190: [15, 391, 285, 390, 864, 894], 191: [914, 915, 285, 857, 858, 15, 391, 856, 390, 1008, 948, 864, 658, 894], 192: [733, 734, 735, 736, 641], 193: [730, 422, 648, 731, 733, 734, 1392, 735, 736, 641], 194: [739, 740, 742, 744, 741, 743, 642], 195: [739, 742, 743, 642], 196: [51, 185, 874, 878, 879, 880, 12, 875, 876, 202, 746, 13, 184], 197: [881, 883, 884, 768], 198: [887, 888, 889, 843, 769], 199: [1052, 1053, 1054, 1055, 1056, 1060, 743, 744, 957], 200: [1134, 1137, 1138, 1071], 201: [552, 625, 1296, 93, 1151, 401, 110, 1391, 423, 541, 1295, 318, 1304, 160, 369, 482, 1140], 202: [1303, 1304, 1309, 1306, 1308, 605, 602, 603, 604, 1110, 1305, 1310, 48, 232, 1285], 203: [58, 1305, 1306, 602, 603, 604, 1307, 1310, 19, 232, 323, 688, 122, 1188, 1285], 204: [572, 1311, 63, 540, 602, 603, 604, 1305, 1188, 307, 1213, 655, 1355, 68, 1285], 205: [1321, 1322, 1287], 206: [1338, 1341, 1340, 1290], 207: [1338, 1339, 1340, 1341, 879, 1290], 208: [163, 1344, 1345, 164, 1347, 1346, 1291], 209: [1351, 1356, 1350, 187, 487, 45, 55, 316, 1383, 1385, 1106, 1228, 1292], 210: [1171, 891, 1172, 1173, 1030, 1174, 1145], 211: [891, 1172, 1173, 1174, 763, 769, 1030, 1031, 1033, 1052, 1068, 1145], 212: [888, 889, 1178, 885, 887, 886, 841, 1176, 1177, 890, 769, 891, 1173, 843, 1146], 213: [888, 885, 887, 889, 1178, 769, 1173, 1177, 886, 890, 843, 1146], 214: [833, 1361, 1362, 1363, 1294], 215: [37, 35, 535], 216: [156, 506], 217: [666, 667, 1258, 1394, 668, 670, 1204, 1391, 1395, 1300, 37, 559, 630, 1107, 1213, 1191], 218: [24, 101, 666, 667, 93, 1258, 1393, 559, 630, 662, 1104, 1107, 1204, 1213, 1300, 1191], 219: [1391, 666, 667, 1258, 1078, 1080, 1081, 1394, 1395, 1214, 1198, 1204, 1300, 559, 630, 662, 1107, 1213, 1191], 220: [1383, 1385, 155, 241, 1382, 1370, 1386, 111, 1384, 150, 292, 458, 479, 977, 376, 459, 1365, 62, 1366, 1182], 221: [155, 1383, 1385, 1382, 62, 292, 241, 1370, 1384, 458, 459, 461, 1386, 1365, 1366, 111, 150, 479, 1182], 222: [400, 419, 1387, 412, 1392, 1398, 1397, 1400, 1399, 1396], 223: [400, 1387, 1392, 1398, 1396], 224: [656, 1313, 1317, 1316, 1318, 1319, 1157, 1274, 1286], 225: [1379, 1305, 1304, 40, 293, 1309, 161, 421, 1377, 1378, 1381, 225, 1380, 448, 449, 1124, 1280, 433, 923, 924, 1062, 1074, 1075, 1213, 1188]}\n"]}]},{"cell_type":"markdown","source":["# Sử dụng whoosh"],"metadata":{"id":"OOlAh0PKjlCQ"}},{"cell_type":"code","source":["pip install whoosh flask"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qTTnu57Lkzyq","executionInfo":{"status":"ok","timestamp":1677849147590,"user_tz":-420,"elapsed":6147,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"6bff716d-cf33-4835-eef2-f39a42b61e67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: whoosh in /usr/local/lib/python3.8/dist-packages (2.7.4)\n","Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (2.2.3)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from flask) (8.1.3)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/dist-packages (from flask) (2.1.2)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.8/dist-packages (from flask) (2.2.3)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from flask) (3.1.2)\n","Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from flask) (6.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->flask) (3.15.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->flask) (2.1.2)\n"]}]},{"cell_type":"code","source":["!mkdir ind"],"metadata":{"id":"1BqISqLElL23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from whoosh.index import create_in\n","from whoosh.fields import *\n","from whoosh.analysis import StandardAnalyzer\n","from whoosh.writing import AsyncWriter\n","\n","schema = Schema(docid=STORED(), content=TEXT(stored=True, analyzer=StandardAnalyzer()))\n","ix = create_in(\"ind\", schema)\n","writer = AsyncWriter(ix)\n","for i in range(len(documents)):\n","  writer.add_document(docid=\"{}\".format(i+1), content=documents[i])\n","writer.commit()"],"metadata":{"id":"fzaJsyzKjpY5","executionInfo":{"status":"ok","timestamp":1677850123167,"user_tz":-420,"elapsed":3,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["queries[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"wbIj0eO2ppXg","executionInfo":{"status":"ok","timestamp":1677849965174,"user_tz":-420,"elapsed":14,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"32a1b7f4-35b0-4b2d-c805-750674829a4a"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft .'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["from whoosh import qparser\n","from whoosh import scoring\n","import whoosh.index as index\n","\n","ind = index.open_dir(\"ind\")\n","searcher = ind.searcher(weighting=scoring.TF_IDF())"],"metadata":{"id":"E4bAuqkEprmG","executionInfo":{"status":"ok","timestamp":1677852848177,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["def use_whoose(query):\n","    parser = qparser.QueryParser(\"content\", ind.schema, group=qparser.OrGroup)\n","    query = parser.parse(queries[0])\n","    results = searcher.search(query, limit=None)\n","    ans = []\n","    for i in range(len(results)):\n","        ans.append(int(results[i][\"docid\"]))\n","    return ans"],"metadata":{"id":"v2WQANXZr815","executionInfo":{"status":"ok","timestamp":1677852849875,"user_tz":-420,"elapsed":2,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["xyz = use_whoose(queries[0])\n","xyz1 = set(xyz[:14])\n","xyz2 = set(relevance[1])\n","xyz3= len(xyz1.intersection(xyz2))\n","print('Precision:', xyz3/len(xyz1))\n","print('Recall:', xyz3/len(xyz2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-rEN_NmsbvB","executionInfo":{"status":"ok","timestamp":1677852815844,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"9e92947a-511f-4d7e-8fa9-e251ba488dc9"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.42857142857142855\n","Recall: 0.20689655172413793\n"]}]},{"cell_type":"code","source":["prec_lst = []\n","recall_lst = []\n","for i in range(225):\n","    xyz = use_whoose(queries[i])\n","    xyz1 = set(xyz)\n","    xyz2 = set(relevance[i + 1])\n","    xyz3= len(xyz1.intersection(xyz2))\n","    prec_lst.append(xyz3/len(xyz1))\n","    recall_lst.append(xyz3/len(xyz2))"],"metadata":{"id":"5ttKXcSIuQf1","executionInfo":{"status":"ok","timestamp":1677852957789,"user_tz":-420,"elapsed":10230,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["prec = sum(prec_lst) / len(prec_lst)\n","rec = sum(recall_lst) / len(recall_lst)\n","print('Precision:', prec)\n","print('Recall:', rec)\n","print((2*prec*rec)/(prec+rec))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70Dnke9utymY","executionInfo":{"status":"ok","timestamp":1677852937759,"user_tz":-420,"elapsed":8,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"2f7d5b80-1a53-49a0-8149-327ad8dbe257"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.006332665330661314\n","Recall: 0.3723777399074151\n","0.012453545351832917\n"]}]},{"cell_type":"code","source":["print(prec_lst)\n","error_idx = []\n","for i in range(len(prec_lst)):\n","  if prec_lst[i] == 0:\n","      error_idx.append(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnbMmZMBx4-_","executionInfo":{"status":"ok","timestamp":1677852857532,"user_tz":-420,"elapsed":4,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"7d44a09b-e005-467e-97e1-10935d2c2279"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.04408817635270541, 0.04008016032064128, 0.0, 0.002004008016032064, 0.006012024048096192, 0.0, 0.01002004008016032, 0.012024048096192385, 0.0, 0.008016032064128256, 0.01002004008016032, 0.002004008016032064, 0.002004008016032064, 0.0, 0.002004008016032064, 0.002004008016032064, 0.0, 0.004008016032064128, 0.012024048096192385, 0.004008016032064128, 0.004008016032064128, 0.002004008016032064, 0.02404809619238477, 0.006012024048096192, 0.012024048096192385, 0.004008016032064128, 0.0, 0.0, 0.006012024048096192, 0.006012024048096192, 0.004008016032064128, 0.0, 0.006012024048096192, 0.008016032064128256, 0.0, 0.002004008016032064, 0.006012024048096192, 0.01002004008016032, 0.012024048096192385, 0.014028056112224449, 0.004008016032064128, 0.002004008016032064, 0.002004008016032064, 0.002004008016032064, 0.012024048096192385, 0.01603206412825651, 0.012024048096192385, 0.01603206412825651, 0.0, 0.002004008016032064, 0.004008016032064128, 0.0, 0.006012024048096192, 0.01002004008016032, 0.006012024048096192, 0.01002004008016032, 0.01603206412825651, 0.002004008016032064, 0.0, 0.002004008016032064, 0.002004008016032064, 0.002004008016032064, 0.002004008016032064, 0.004008016032064128, 0.008016032064128256, 0.008016032064128256, 0.008016032064128256, 0.006012024048096192, 0.004008016032064128, 0.01002004008016032, 0.012024048096192385, 0.018036072144288578, 0.026052104208416832, 0.008016032064128256, 0.008016032064128256, 0.012024048096192385, 0.01002004008016032, 0.006012024048096192, 0.0, 0.0, 0.006012024048096192, 0.006012024048096192, 0.006012024048096192, 0.012024048096192385, 0.006012024048096192, 0.002004008016032064, 0.006012024048096192, 0.002004008016032064, 0.004008016032064128, 0.004008016032064128, 0.008016032064128256, 0.014028056112224449, 0.0, 0.012024048096192385, 0.004008016032064128, 0.018036072144288578, 0.01603206412825651, 0.006012024048096192, 0.008016032064128256, 0.004008016032064128, 0.004008016032064128, 0.004008016032064128, 0.002004008016032064, 0.004008016032064128, 0.002004008016032064, 0.002004008016032064, 0.014028056112224449, 0.012024048096192385, 0.006012024048096192, 0.0, 0.008016032064128256, 0.0, 0.004008016032064128, 0.004008016032064128, 0.008016032064128256, 0.006012024048096192, 0.004008016032064128, 0.008016032064128256, 0.0, 0.002004008016032064, 0.002004008016032064, 0.0, 0.004008016032064128, 0.002004008016032064, 0.006012024048096192, 0.002004008016032064, 0.004008016032064128, 0.004008016032064128, 0.008016032064128256, 0.008016032064128256, 0.004008016032064128, 0.006012024048096192, 0.004008016032064128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004008016032064128, 0.004008016032064128, 0.002004008016032064, 0.002004008016032064, 0.002004008016032064, 0.002004008016032064, 0.0, 0.002004008016032064, 0.0, 0.0, 0.004008016032064128, 0.006012024048096192, 0.006012024048096192, 0.004008016032064128, 0.006012024048096192, 0.004008016032064128, 0.012024048096192385, 0.03406813627254509, 0.008016032064128256, 0.008016032064128256, 0.004008016032064128, 0.0, 0.0, 0.006012024048096192, 0.01002004008016032, 0.0, 0.004008016032064128, 0.006012024048096192, 0.002004008016032064, 0.0, 0.01002004008016032, 0.006012024048096192, 0.004008016032064128, 0.0, 0.006012024048096192, 0.004008016032064128, 0.004008016032064128, 0.008016032064128256, 0.008016032064128256, 0.006012024048096192, 0.0, 0.0, 0.006012024048096192, 0.014028056112224449, 0.01002004008016032, 0.01002004008016032, 0.022044088176352707, 0.002004008016032064, 0.018036072144288578, 0.006012024048096192, 0.008016032064128256, 0.01603206412825651, 0.0, 0.0, 0.002004008016032064, 0.0, 0.02404809619238477, 0.004008016032064128, 0.002004008016032064, 0.002004008016032064, 0.004008016032064128, 0.02004008016032064, 0.01603206412825651, 0.014028056112224449, 0.012024048096192385, 0.002004008016032064, 0.006012024048096192, 0.01002004008016032, 0.006012024048096192, 0.01002004008016032, 0.0, 0.002004008016032064, 0.004008016032064128, 0.004008016032064128, 0.006012024048096192, 0.002004008016032064, 0.002004008016032064, 0.014028056112224449, 0.02004008016032064, 0.01603206412825651, 0.008016032064128256, 0.008016032064128256, 0.002004008016032064, 0.002004008016032064, 0.004008016032064128, 0.028056112224448898]\n"]}]},{"cell_type":"code","source":["for idx in error_idx:\n","    print(queries[idx])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"971sWO7EyTZZ","executionInfo":{"status":"ok","timestamp":1677852362822,"user_tz":-420,"elapsed":10,"user":{"displayName":"Hai Phan Thanh","userId":"12736271334611174604"}},"outputId":"0dfe91b8-5043-46a6-eef5-22c8734c5546"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["what problems of heat conduction in composite slabs have been solved so far .\n","what theoretical and experimental guides do we have as to turbulent couette flow behaviour .\n","papers on internal /slip flow/ heat transfer studies .\n","papers on shock-sound wave interaction .\n","can the three-dimensional problem of a transverse potential flow about a body of revolution be reduced to a two-dimensional problem .\n","how is the design of ring or part ring wings by linear theory affected by thickness .\n","what application has the linear theory design of curved wings .\n","to find an approximate correction for thickness in slender thin-wing theory .\n","are there any papers dealing with acoustic wave propagation in reacting gases .\n","can the three-point boundary-value problem for the blasius equation be integrated numerically,  using suitable transformations,  without iteration on the boundary conditions .\n","what is the available information pertaining to the effect of slight rarefaction on boundary layer flows (the slip effect) .\n","how much is known about boundary layer flows along non-circular cylinders .\n","have any aerodynamic derivatives been measured at hypersonic mach numbers and comparison been made with theoretical work .\n","are methods of measuring aerodynamic derivatives available which could be adopted for use in short running time facilities .\n","can methane-air combustion product be used as a hypersonic test medium and predict, within experimental accuracies, the results obtained in air .\n","can increasing the edge loading of a plate beyond the critical value for buckling change the buckling mode .\n","has the solution of the clamped plate problem,  in the classical theory of bending,  been reduced to two successive membrane boundary value problems .\n","what is the effect of initial axisymmetric deviations from circularity on the non linear (large-deflection) load-deflection response of cylinders under hydrostatic pressure .\n","what analytical investigations have been made of the stability of conical shells . how do the results compare with experiment .\n","is it possible to correlate the results on the creep buckling of widely different structures within the framework of a single theory .\n","what are the experimental results for the creep buckling of columns .\n","what are the results for the creep buckling of round tubes under external pressure .\n","have any analytical studies been conducted on the time-to-failure mechanism associated with creep collapse for a long circular cylindrical shell which exhibits both primary and secondary creep as well as elastic deformations under various distributed force systems .\n","has the effect of initial stresses,  on the frequencies of vibration of circular cylindrical shells,  been investigated .\n","has the effect of the change of initial pressure due to deformation,  on the frequencies of vibration of circular cylindrical shells been investigated .\n","does a membrane theory exist by which the behaviour of pressurized membrane cylinders in bending can be predicted .\n","papers on small deflection theory for buckling of sandwich cylinders .\n","has anyone developed an analysis which accurately establishes the large deflection behaviour of conical shells .\n","is there an integral method to give a single and sufficiently accurate method of calculating the laminar separate point for various incompressible and compressible boundary layers with zero heat transfer .\n","what accurate or exact solutions of the laminar separation point for various incompressible and compressible boundary layers with zero heat transfer are available .\n","are the stable profiles of a compressible boundary layer induced by a moving wave known .\n","what approximate solutions are known to the indirect problem of transonic flow in the throat of a nozzle,  i.e. finding a nozzle which has a given axial velocity distribution .\n","references on lyapunov's method on the stability of linear differential equations with periodic coefficients .\n","how does scale height vary with altitude in an atmosphere .\n","jet interference with supersonic flows theoretical papers .\n","papers dealing with uniformly loaded sectors .\n","general methods of solving clamped plate problems .\n","in the problem of the buckling strength of uniform circular cylinders loaded in axial compression,  does the linear solution help with improving the non-linear one .\n","has anyone analytically investigated the stabilizing influence of soft elastic cores on the buckling strength of cylindrical shells subjected to non-uniform external pressure .\n"]}]},{"cell_type":"markdown","source":["# **3. Thống kê mục từ**"],"metadata":{"id":"CKVLr40m52pm"}},{"cell_type":"markdown","source":["Ta sẽ xây dựng cấu trúc dữ liệu để biểu diễn thông tin mục từ của tài liệu.\n","*word_lst*: từ điển lưu trữ thông tin của các mục từ bao gồm nội dung chuỗi kí tự, chỉ số tài liệu và tần số xuất hiện trong tài liệu tương ứng theo cấu trúc sau:\n","\n","```\n","word_lst = {\n","[mục từ 1]: { [chỉ số tài liệu 1]: [tần số],\n","\t          [chỉ số tài liệu 2]: [tần số],\n","\t        … }\n","[mục từ 2]: { [chỉ số tài liệu 1]: [tần số],\n","\t          [chỉ số tài liệu 2]: [tần số],\n","\t        … }\n","… }\n","```\n","\n","\n"],"metadata":{"id":"o98lyfwyVwzH"}},{"cell_type":"code","source":["'''\n","Hàm này dùng để cập nhật thông tin của các mục từ trong từ điển word_lst\n","# Input:\n","# + id: id của câu\n","# + term: term của tài liệu\n","# + word_lst: từ điển word_lst chứa thông tin\n","# Output: từ điển word_lst sau khi đã khi đã cập nhật thông tin term\n","'''\n","def update_word_lst(id, word, word_lst):\n","    if word in word_lst:\n","        if id in word_lst[word]:\n","            # Cập nhật tần số xuất hiện của từ đó lên 1\n","            word_lst[word][id] += 1\n","        else:\n","            # Thêm chỉ số tài liệu và tần số = 1 tương ứng với mục từ mới\n","            word_lst[word][id] = 1\n","    else:\n","        # Thêm mục từ mới vào trong word_lst và chỉ số tài liệu, tần số = 1 tương ứng\n","        word_lst[word] = {id: 1}\n","    return word_lst"],"metadata":{"id":"dwbGC7JQZYDb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hàm này dùng để phân tách mục từ từ 1 câu\n","def create_words(sentence):\n","    words = [] \n","    # Remove punctuation and numbers. Split on whitespace\n","    regex = r\"[ .,()0123456789=:+-/']\\s*\"\n","    words = re.split(regex, sentence)\n","    # Use filter(None, ) to remove empty element after splitting string\n","    words = filter(None, words)\n","    return words"],"metadata":{"id":"kkJpKBWqq4KL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_vocab_lst(inverted_index):\n","    vocab_lst = {}\n","    for term in inverted_index:\n","        freq = len(inverted_index[term])\n","        no_of_docs = sum(inverted_index[term].values())\n","        vocab_lst[term] = [freq, no_of_docs]\n","    return vocab_lst"],"metadata":{"id":"2f4VPW6H-2jl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hàm này dùng để cập nhật thông tin toàn bộ mục từ của 1 câu trong từ điển word_lst\n","def create_word_lst(id, sentence, word_lst):\n","    words = create_words(sentence)\n","    for word in words:\n","        # Update word in word_lst\n","        word_lst = update_word_lst(id, word, word_lst)\n","    return word_lst"],"metadata":{"id":"RtUmZGb7tR7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_lst = {}\n","idx = 1\n","for document in documents:\n","    word_lst = create_word_lst(idx, document, word_lst)\n","    idx += 1\n","print(word_lst)"],"metadata":{"id":"DEmP4cxMrezb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In ra màn hình kết quả thống kê các mục từ có trong tập tài liệu, trong đó mỗi dòng có định dạng: \n","\n","```\n","<mục từ> <số lượng tài liệu chứa mục từ> <tần số>\n","```\n","\n"],"metadata":{"id":"6CvYm0-AWpEY"}},{"cell_type":"code","source":["word_info_lst = create_vocab_lst(word_lst)\n","res_path = '/content/drive/MyDrive/FOLDER MÔN HỌC/HK1(2022-2023)/CS419.N11 - Truy xuất thông tin/Bài tập/word_lst.txt'\n","with open(res_path, 'w') as file:\n","    for word in word_info_lst:\n","        string = word + ' ' + str(word_info_lst[word][0]) + ' ' + str(word_info_lst[word][1]) + '\\n'\n","        file.write(string)"],"metadata":{"id":"zWQeK7Fwbffp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Số lượng mục từ có trong toàn bộ tập tài liệu là:', len(word_info_lst))"],"metadata":{"id":"LMh_Qu6kYYQJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4. Xác định term**"],"metadata":{"id":"cyCzgLFaA_JH"}},{"cell_type":"markdown","source":["*Terms* của tài liệu được xác định theo các bước như sau:\n","\n","**Bước 1.** Ngắt các token trong tài liệu bởi dấu cách.\n","\n","**Bước 2.** Với mỗi token:\n","*   **Bước 2.1.** Loại bỏ các kí tự dấu câu và các chữ số.\n","*   **Bước 2.2.** Loại bỏ các token là *stopwords* trong tài liệu.\n","*   **Bước 2.3.** Sử dụng kĩ thuật *stemming* để lấy từ gốc trong câu.\n","*   **Bước 2.4.** Loại bỏ những từ gốc chỉ có chứa 3 kí tự.\n","\n","Kết quả sau **bước 2** cho ta danh sách các *terms* của tài liệu."],"metadata":{"id":"lIWBd-MLyxMr"}},{"cell_type":"markdown","source":["Ta sẽ xây dựng cấu trúc dữ liệu để biểu diễn thông tin mục từ của tài liệu.\n","*inverted_indext*: từ điển lưu trữ thông tin của các *terms* bao gồm nội dung chuỗi kí tự, chỉ số tài liệu và tần số xuất hiện trong tài liệu tương ứng theo cấu trúc sau:\n","\n","```\n","inverted_index = {\n","[term 1]: { [chỉ số tài liệu 1]: [tần số],\n","\t        [chỉ số tài liệu 2]: [tần số],\n","\t       … }\n","[term 2]: { [chỉ số tài liệu 1]: [tần số],\n","\t        [chỉ số tài liệu 2]: [tần số],\n","\t      … }\n","… }\n","```"],"metadata":{"id":"on4JnEzlZN7P"}},{"cell_type":"code","source":["'''\n","Hàm này dùng để cập nhật thông tin của các mục từ trong từ điển inverted_file\n","# Input:\n","# + id: id của câu\n","# + term: term của tài liệu\n","# + inverted_index: từ điển inverted_index chứa thông tin\n","# Output: từ điển inverted_index sau khi đã khi đã cập nhật thông tin term\n","'''\n","def update_inverted_index(id, term, inverted_index):\n","    if term in inverted_index:\n","        if id in inverted_index[term]:\n","            inverted_index[term][id] += 1\n","        else:\n","            inverted_index[term][id] = 1\n","    else:\n","        inverted_index[term] = {id: 1}\n","    return inverted_index"],"metadata":{"id":"45gzXSN8N0PD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hàm này dùng để phân tách term từ 1 câu\n","def create_terms(sentence):\n","    terms = []\n","    # Remove punctuation and numbers. Split on whitespace\n","    regex = r\"[ .,()0123456789=:+-/']\\s*\"\n","    word_lst = re.split(regex, sentence)\n","    # Use filter(None, ) to remove empty element after splitting string\n","    word_lst = filter(None, word_lst)\n","    for word in word_lst:\n","        # Remove stopwords\n","        stopword_lst = stopwords.words('english')\n","        if word in stopword_lst:\n","            continue\n","        # Perform stemming\n","        stemmer = SnowballStemmer(\"english\")\n","        stem_word = stemmer.stem(word)\n","        # Remove 1 character\n","        if len(stem_word) < 3:\n","            continue\n","        terms.append(stem_word)\n","    return terms"],"metadata":{"id":"WjnypivHIFei"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hàm này dùng để cập nhật thông tin toàn bộ terms của 1 câu trong từ điển inverted_index\n","# Input:\n","# + id: id của câu\n","# + term: term của tài liệu\n","# + inverted_index: từ điển inverted_index chứa thông tin\n","# Output: từ điển inverted_index sau khi đã khi đã cập nhật thông tin toàn bộ terms\n","def create_inverted_index(id, sentence, inverted_index):\n","    terms = create_terms(sentence)\n","    for term in terms:\n","        # Update term in inverted_index\n","        inverted_index = update_inverted_index(id, term, inverted_index)\n","    return inverted_index"],"metadata":{"id":"FxP_oeEwBCD1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inverted_index = {}\n","idx = 1\n","for document in documents:\n","    inverted_index = create_inverted_index(idx, document, inverted_index)\n","    idx += 1\n","print(inverted_index)"],"metadata":{"id":"iKgT4OH399Fl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **5. Lập chỉ mục**"],"metadata":{"id":"7mjwgrUqBDZf"}},{"cell_type":"markdown","source":["In ra màn hình danh sách tập từ vựng, trong đó mỗi dòng có định dạng: \n","\n","```\n","<term> <số lượng tài liệu chứa term> <tần số>\n","```\n","\n"],"metadata":{"id":"XacwwdsmAK4O"}},{"cell_type":"code","source":["vocab_lst = create_vocab_lst(inverted_index)\n","res_path = '/content/drive/MyDrive/FOLDER MÔN HỌC/HK1(2022-2023)/CS419.N11 - Truy xuất thông tin/Bài tập/vocab_lst.txt'\n","with open(res_path, 'w') as file:\n","    for term in vocab_lst:\n","        string = term + ' ' + str(vocab_lst[term][0]) + ' ' + str(vocab_lst[term][1]) + '\\n'\n","        file.write(string)"],"metadata":{"id":"G55JskrM_jEf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Số lượng terms có trong toàn bộ tập tài liệu là:', len(inverted_index))"],"metadata":{"id":"PBv7bDwtCbdu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In ra màn hình danh sách posting, trong đó mỗi dòng có định dạng: \n","\n","```\n","<term> <chỉ số tài liệu> <tần số>\n","```\n"],"metadata":{"id":"wSAcKi3OAm99"}},{"cell_type":"code","source":["res_path = '/content/drive/MyDrive/FOLDER MÔN HỌC/HK1(2022-2023)/CS419.N11 - Truy xuất thông tin/Bài tập/posting_lst.txt'\n","with open(res_path, 'w') as file:\n","    for term in inverted_index:\n","        idx = 1\n","        for id in inverted_index[term]:\n","            string = term + ' ' + str(id) + ' ' + str(inverted_index[term][id]) + '\\n'\n","            file.write(string)"],"metadata":{"id":"WH9mPQJCAgHM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **6. Tìm kiếm theo mô hình boolean**"],"metadata":{"id":"KsMcEkw_6EEe"}},{"cell_type":"code","source":["'''\n","Input:\n","+ query: câu truy vấn\n","+ inverted_index: từ điển chứa thông tin\n","Output: danh sách index_lst chứa danh sách id của tài liệu tương ứng với\n","câu truy vấn query sử dụng mô hình tìm kiếm boolean chỉ sử dụng phép toán OR\n","'''\n","def boolean_retrieval(query, inverted_index):\n","    retrieved_indexes = []\n","    query_terms = create_terms(query)\n","    for term in query_terms:\n","        if term in inverted_index:\n","            retrieved_indexes += inverted_index[term]\n","    return list(set(retrieved_indexes))"],"metadata":{"id":"BWfzEArlHEgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(boolean_retrieval(queries[1], inverted_index))"],"metadata":{"id":"k2nys-EHdat-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **6.2 Tìm kiếm theo mô hình Vector Space**"],"metadata":{"id":"6gHcCX9fZ7Il"}},{"cell_type":"code","source":["def termFrequencyInDoc(word_info_lst, documents):\n","    tf_docs = {}\n","    for term in word_info_lst.keys():\n","        tf_docs[term] = {}\n","        for docs_id in range(len(documents)):\n","            doc = documents[docs_id]\n","            tf_docs[term][docs_id] = np.log2(1 + doc.count(term))\n","    return tf_docs\n","tf_score = termFrequencyInDoc(word_info_lst, documents)"],"metadata":{"id":"8PFrYiEiZ6Bi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inverseFrequencyInDoc(word_info_lst, documents):\n","    idf_docs = {}\n","    length = len(documents)\n","    for term in word_info_lst.keys():\n","        a = word_info_lst[term][0]\n","        idf_docs[term] = np.log2(length / (1 + a))\n","    return idf_docs\n","idf_score = inverseFrequencyInDoc(word_info_lst, documents)"],"metadata":{"id":"iWYXXlv1b8lB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tf_idf_score(tf_weight, idf_weight, word_info_lst, documents):\n","    tf_idf_score = {}\n","    for term in word_info_lst.keys():\n","        tf_idf_score[term] = {}\n","        for docs_id in range(len(documents)):\n","            doc = documents[docs_id]\n","            tf_idf_score[term][docs_id] = tf_weight[term][docs_id] * idf_weight[term]\n","    return tf_idf_score\n","tf_idf = tf_idf_score(tf_score, idf_score, word_info_lst, documents)\n"],"metadata":{"id":"FHeieKXQb9nC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vectorSpaceModel(query_input, documents, tf_idf, word_info_lst, number_of_selected):\n","    query_vocab = []\n","    query = list(create_words(query_input))\n","    for word in query:\n","        flag = False\n","        for term in word_info_lst:\n","            if word == term: flag = True\n","        if flag == True:\n","            if word not in query_vocab:\n","                query_vocab.append(word)\n","    query_wc = {}\n","    for word in query_vocab:\n","        query_wc[word] = query.count(word)\n","        \n","    relevance_scores = {}\n","    for docs_id in range(len(documents)):\n","        score = 0\n","        for word in query_vocab:\n","            score += query_wc[word] * tf_idf[word][docs_id]\n","        relevance_scores[docs_id + 1] = score\n","    sorted_value = OrderedDict(sorted(relevance_scores.items(), key=lambda x: x[1], reverse = True))\n","    top_values = {k: sorted_value[k] for k in list(sorted_value)[:number_of_selected]}\n","    return top_values"],"metadata":{"id":"Be0r-dpbb-2J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **6.3 Tìm kiếm với mô hình Latent Semantic Index (LSI)**"],"metadata":{"id":"v58jKBF4YJEc"}},{"cell_type":"code","source":["def LSI(queries, documents, number_of_selected):\n","    query = [queries]\n","    D = documents\n","    # Vector hoá tập tài liệu có dạng (chỉ số tài liệu, keys của term) = tần số của term trong tài liệu đó\n","    vectorizer = CountVectorizer()\n","    X = vectorizer.fit_transform(D)\n","    A = X.T.toarray()\n","    # Phân tích ma trận tài liệu thành ba ma trận theo phương pháp Singular Value Decomposition (SVD) \n","    # Sử dụng thư viện numpy.linalg.svd để phân tích\n","    [u,s,vt] = svd(A, full_matrices=False)\n","\n","    # Vector hoá câu truy vấn \n","    q = vectorizer.transform(query)\n","    q = q.toarray()\n","    \n","    q = np.matmul(np.matmul(q,u),np.linalg.inv(np.diag(s)))\n","    result = []\n","    for i in range(len(vt)):\n","        value = np.dot(q,vt[:,i])/(np.linalg.norm(q)*np.linalg.norm(vt[:,i]))\n","        result.append(value)\n","    result_sorted = sorted(result)[-number_of_selected:]\n","    \n","    # Lấy ra những tài liệu có độ chính xác cao nhất khi so khớp câu truy vấn\n","    top_docs = []\n","    for value in result_sorted:\n","        top_docs.append(result.index(value) + 1)\n","    return top_docs"],"metadata":{"id":"rst1q-OXYKKP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **7. Duyệt sơ lược kết quả và nhận xét**"],"metadata":{"id":"4DggOwfC6U3c"}},{"cell_type":"code","source":["# Dùng for duyệt một số câu truy vấn đầu. So sánh đối chiếu với\n","# kết quả trong relevance và đưa ra nhận xét\n","res = []\n","precision_lst = []\n","recall_lst = []\n","f_score_lst = []\n","no_queries = len(queries)\n","for idx in range(0, no_queries):\n","    retrieved_indexes = set(boolean_retrieval(queries[idx], inverted_index))\n","    relevant_indexes = set(relevance[idx+1])\n","    no_relevant_docs_retrieved = len(retrieved_indexes & relevant_indexes)\n","    \n","    precision, recall, f_score = 0, 0, 0\n","\n","    if len(retrieved_indexes) != 0:\n","        precision = round(no_relevant_docs_retrieved/len(retrieved_indexes), 2)\n","    if len(relevant_indexes) != 0:\n","        recall = round(no_relevant_docs_retrieved/len(relevant_indexes), 2)\n","    if precision * recall != 0:\n","        f_score = round((2 * precision * recall) / (precision + recall), 2)\n","    \n","    precision_lst.append(precision)\n","    recall_lst.append(recall)\n","    f_score_lst.append(f_score)"],"metadata":{"id":"D3JWeCNUBO84"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In ra màn hình kết quả độ đo sử dụng đánh giá mô hình bài toán, trong đó mỗi dòng có định dạng: \n","\n","```\n","<chỉ số của câu truy vấn> <Độ chính xác> <Độ phủ> <Độ đo F>\n","```\n","\n"],"metadata":{"id":"F1v8nxRAf8zM"}},{"cell_type":"code","source":["res_path = '/content/drive/MyDrive/FOLDER MÔN HỌC/HK1(2022-2023)/CS419.N11 - Truy xuất thông tin/Bài tập/experimental_result.txt'\n","with open(res_path, 'w') as file:\n","    for idx in range(len(precision_lst)):\n","        string = str(idx+1) + ' ' + str(precision_lst[idx]) + ' ' + str(recall_lst[idx]) + ' ' + str(f_score_lst[idx]) + '\\n'\n","        file.write(string)"],"metadata":{"id":"tcLa5mG1gR74"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Độ chính xác trung bình:', round(sum(precision_lst)/len(precision_lst), 2))\n","print('Độ phủ trung bình:', round(sum(recall_lst)/len(recall_lst), 2))\n","print('Độ đo F trung bình:', round(sum(f_score_lst)/len(f_score_lst), 2))"],"metadata":{"id":"X_g3kyq4gwqD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **7.2 Đánh giá độ chính xác của mô hình Vector Space**"],"metadata":{"id":"O77NR6AecHBR"}},{"cell_type":"code","source":["'''\n","Dùng mô hình truy xuất thông tin Vector Space, \n","output trả về là toàn bộ tài liệu.\n","'''\n","avg_precision_VSM = []\n","avg_recall_VSM = []\n","avg_f_score_VSM = []\n","precision_lst_VSM = []\n","recall_lst_VSM = []\n","f_score_lst_VSM = []\n","beta = 1.5\n","no_queries = len(queries)\n","\n","# list_num_docs = [5,10,20,30,40,50,60,80,100,150,225]   \n","list_num_docs = [15]\n","for num_docs in list_num_docs:\n","    for query_index in range(0, no_queries):\n","        retrieved_indexes = set(vectorSpaceModel(queries[query_index], documents, tf_idf, word_info_lst, num_docs))\n","        relevant_indexes = set(relevance[query_index + 1])\n","        # Lập danh sách số lượng tài liệu phù hợp nhất \n","        # retrieved_indexes_set = set(retrieved_indexes[:_step_docs])\n","        no_relevant_docs_retrieved = len(retrieved_indexes & relevant_indexes)\n","        precision, recall, f_score, e_measure = 0, 0, 0, 0\n","        if len(retrieved_indexes) != 0:\n","            precision = round(no_relevant_docs_retrieved/len(retrieved_indexes), 2)\n","        if len(retrieved_indexes) != 0:\n","            recall = round(no_relevant_docs_retrieved/len(relevant_indexes), 2)\n","        if precision * recall != 0:\n","            f_score = round((2 * precision * recall) / (precision + recall), 2)\n","        precision_lst_VSM.append(precision)\n","        recall_lst_VSM.append(recall)\n","        f_score_lst_VSM.append(f_score)\n","    avg_precision_VSM.append(round(sum(precision_lst_VSM) / len(precision_lst_VSM), 2))\n","    avg_recall_VSM.append(round(sum(recall_lst_VSM) / len(recall_lst_VSM), 2))\n","    avg_f_score_VSM.append(round(sum(f_score_lst_VSM)/len(f_score_lst_VSM), 2))"],"metadata":{"id":"qEOtM16DcLmi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr = np.column_stack((precision_lst_VSM, recall_lst_VSM))\n","import pandas as pd\n","evaluation = arr[arr[:, 1].argsort()]\n","recall_sorted = []\n","precision_sorted = []\n","for idx in range(evaluation.shape[0]):\n","    precision_sorted.append(evaluation[idx][0])\n","    recall_sorted.append(round(evaluation[idx][1],1))\n","df = pd.DataFrame({\"Recall\": recall_sorted, \"Precision\": precision_sorted})\n","df_groupby = df.groupby([\"Recall\"]).mean()\n","df_groupby"],"metadata":{"id":"g2P37fhLM6cq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import auc, precision_recall_curve\n","import matplotlib.pyplot as plt\n","fig, ax = plt.subplots(figsize=(6,6))\n","plt.plot(df_groupby, 'r')\n","plt.title(\"Precision - Recall Curve of Vector Space Model with top 15 docs\")\n","ax.set_xlabel(\"Recall\")\n","ax.set_ylabel(\"Precision\")"],"metadata":{"id":"CQYTDqYgcqJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Độ chính xác trung bình :', round(sum(precision_lst_VSM)/len(precision_lst_VSM), 2))\n","print('Độ phủ trung bình:', round(sum(recall_lst_VSM)/len(recall_lst_VSM), 2))\n","print('Độ đo F trung bình:', round(sum(f_score_lst_VSM)/len(f_score_lst_VSM), 2))\n"],"metadata":{"id":"UUxQ77L3M82k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7.3 Đánh giá độ chính xác của mô hình Latent Semantic Index"],"metadata":{"id":"ryxAEXmmipvY"}},{"cell_type":"code","source":["'''\n","Dùng mô hình truy xuất thông tin LSI, \n","output trả về là toàn bộ tài liệu.\n","'''\n","avg_precision_LSI = []\n","avg_recall_LSI = []\n","precision_lst_LSI = []\n","recall_lst_LSI = []\n","f_score_lst_LSI = []\n","avg_f_score_LST = []\n","no_queries = len(queries)\n","\n","# list_num_docs = [5,10,20,30,40,50,60,80,100,150,225]   \n","list_num_docs = [15]\n","for num_docs in list_num_docs:\n","    for query_index in range(0, no_queries):\n","        retrieved_indexes = set(LSI(queries[query_index], documents, num_docs))\n","        relevant_indexes = set(relevance[query_index + 1])\n","        # Lập danh sách số lượng tài liệu phù hợp nhất \n","        # retrieved_indexes_set = set(retrieved_indexes[:_step_docs])\n","        no_relevant_docs_retrieved = len(retrieved_indexes & relevant_indexes)\n","        precision, recall, f_score = 0, 0, 0\n","        if len(retrieved_indexes) != 0:\n","            precision = round(no_relevant_docs_retrieved/len(retrieved_indexes), 2)\n","        if len(retrieved_indexes) != 0:\n","            recall = round(no_relevant_docs_retrieved/len(relevant_indexes), 2)\n","        if precision * recall != 0:\n","            f_score = round((2 * precision * recall) / (precision + recall), 2)\n","        precision_lst_LSI.append(precision)\n","        recall_lst_LSI.append(recall)\n","        f_score_lst_LSI.append(f_score)\n","    avg_precision_LSI.append(round(sum(precision_lst_LSI) / len(precision_lst_LSI), 2))\n","    avg_recall_LSI.append(round(sum(recall_lst_LSI) / len(recall_lst_LSI), 2))\n","    avg_f_score_LST.append(round(sum(f_score_lst_LSI)/len(f_score_lst_LSI), 2))"],"metadata":{"id":"afXm7Zx4izYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr = np.column_stack((precision_lst_LSI, recall_lst_LSI))\n","import pandas as pd\n","evaluation = arr[arr[:, 1].argsort()]\n","recall_sorted = []\n","precision_sorted = []\n","for idx in range(evaluation.shape[0]):\n","    precision_sorted.append(evaluation[idx][0])\n","    recall_sorted.append(round(evaluation[idx][1],1))\n","df = pd.DataFrame({\"Recall\": recall_sorted, \"Precision\": precision_sorted})\n","df_groupby = df.groupby(\"Recall\").mean()\n","df_groupby[\"Precision\"]"],"metadata":{"id":"MQzwIpopi1qT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Độ chính xác trung bình:', round(sum(precision_lst_LSI)/len(precision_lst_LSI), 2))\n","print('Độ phủ trung bình:', round(sum(recall_lst_LSI)/len(recall_lst_LSI), 2))\n","print('Độ đo F trung bình:', round(sum(f_score_lst_LSI)/len(f_score_lst_LSI), 2))"],"metadata":{"id":"uoDzpbw0i9jL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(6,6))\n","plt.plot(df_groupby, 'r')\n","plt.title(\"Precision - Recall Curve of LSI Model top 15 docs\")\n","ax.set_xlabel(\"Recall\")\n","ax.set_ylabel(\"Precision\")"],"metadata":{"id":"6AQ71h24jWRS"},"execution_count":null,"outputs":[]}]}